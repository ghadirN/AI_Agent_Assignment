{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ghadirN/AI_Agent_Assignment/blob/main/the-cozy-oven-bot/business_agent.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# The Cozy Oven"
      ],
      "metadata": {
        "id": "rhNdVZ30Rd_g"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "installing"
      ],
      "metadata": {
        "id": "3C3XJPt5RpFB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "OFLHJLu9Pzp8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7b7b2938-811d-465a-ba3b-b9d30bdc313c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.12/dist-packages (2.16.0)\n",
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.12/dist-packages (1.2.1)\n",
            "Requirement already satisfied: gradio in /usr/local/lib/python3.12/dist-packages (5.50.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from openai) (4.12.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.10.0 in /usr/local/lib/python3.12/dist-packages (from openai) (0.12.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from openai) (2.12.3)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.12/dist-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.12/dist-packages (from openai) (4.15.0)\n",
            "Requirement already satisfied: aiofiles<25.0,>=22.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (24.1.0)\n",
            "Requirement already satisfied: brotli>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (1.2.0)\n",
            "Requirement already satisfied: fastapi<1.0,>=0.115.2 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.123.10)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.12/dist-packages (from gradio) (1.0.0)\n",
            "Requirement already satisfied: gradio-client==1.14.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (1.14.0)\n",
            "Requirement already satisfied: groovy~=0.1 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.1.2)\n",
            "Requirement already satisfied: huggingface-hub<2.0,>=0.33.5 in /usr/local/lib/python3.12/dist-packages (from gradio) (1.3.4)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (3.1.6)\n",
            "Requirement already satisfied: markupsafe<4.0,>=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (3.0.3)\n",
            "Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.0.2)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (3.11.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from gradio) (25.0)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.2.2)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (11.3.0)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.12/dist-packages (from gradio) (0.25.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.18 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.0.22)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (6.0.3)\n",
            "Requirement already satisfied: ruff>=0.9.3 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.14.14)\n",
            "Requirement already satisfied: safehttpx<0.2.0,>=0.1.6 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.1.7)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.10.0)\n",
            "Requirement already satisfied: starlette<1.0,>=0.40.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.50.0)\n",
            "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.13.3)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.21.1)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.40.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from gradio-client==1.14.0->gradio) (2025.3.0)\n",
            "Requirement already satisfied: websockets<16.0,>=13.0 in /usr/local/lib/python3.12/dist-packages (from gradio-client==1.14.0->gradio) (15.0.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.5.0->openai) (3.11)\n",
            "Requirement already satisfied: annotated-doc>=0.0.2 in /usr/local/lib/python3.12/dist-packages (from fastapi<1.0,>=0.115.2->gradio) (0.0.4)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai) (2026.1.4)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.33.5->gradio) (3.20.3)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.33.5->gradio) (1.2.0)\n",
            "Requirement already satisfied: shellingham in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.33.5->gradio) (1.5.4)\n",
            "Requirement already satisfied: typer-slim in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.33.5->gradio) (0.21.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas<3.0,>=1.0->gradio) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.3)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (0.4.2)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0,>=0.12->gradio) (8.3.1)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.17.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install openai python-dotenv gradio"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "importing libraries and loading all needed enviroments and files"
      ],
      "metadata": {
        "id": "ReJNA2mcRruq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "from datetime import datetime\n",
        "from dotenv import load_dotenv\n",
        "from openai import OpenAI\n",
        "import gradio as gr\n",
        "from google.colab import userdata\n",
        "\n",
        "# --- MODIFIED FOR OPENROUTER ---\n",
        "# This bypasses region blocks and lets you use Llama 3.3 for free/cheap\n",
        "client = OpenAI(\n",
        "  base_url=\"https://openrouter.ai/api/v1\",\n",
        "  api_key=userdata.get(\"OPENROUTER_API_KEY\"), # Add this key to Colab Secrets\n",
        ")\n",
        "# Using a 2026 flagship model that is excellent with tools\n",
        "MODEL_NAME = \"meta-llama/llama-3.3-70b-instruct\"\n",
        "# -------------------------------\n",
        "\n",
        "# Paths for existing business files\n",
        "SUMMARY_PATH = os.path.join(\"me\", \"business_summary.txt\")\n",
        "PDF_PATH = os.path.join(\"me\", \"about_business.pdf\")\n",
        "\n",
        "summary_text = \"\"\n",
        "if os.path.exists(SUMMARY_PATH):\n",
        "    with open(SUMMARY_PATH, \"r\", encoding=\"utf-8\") as f:\n",
        "        summary_text = f.read()\n",
        "else:\n",
        "    summary_text = (\n",
        "        \"The Cozy Oven is a small-batch, artisanal bakery that embodies slow, mindful moments.\"\n",
        "    )\n",
        "\n",
        "# Define where the tools will log their data\n",
        "LEADS_LOG_PATH = \"leads_log.jsonl\"\n",
        "FEEDBACK_LOG_PATH = \"feedback_log.jsonl\"\n",
        "\n",
        "\n",
        "# import os\n",
        "# import json\n",
        "# from datetime import datetime\n",
        "\n",
        "# from dotenv import load_dotenv\n",
        "# from openai import OpenAI\n",
        "# import gradio as gr\n",
        "\n",
        "# # Get Access to The OpenAI API Key\n",
        "# from getpass import getpass\n",
        "# from google.colab import userdata\n",
        "\n",
        "# open_ai_key = userdata.get('OPENAI_API_KEY')\n",
        "# client = OpenAI(api_key=open_ai_key)\n",
        "\n",
        "# # Paths for existing business files\n",
        "# SUMMARY_PATH = os.path.join(\"me\", \"business_summary.txt\")\n",
        "# PDF_PATH = os.path.join(\"me\", \"about_business.pdf\")  # not read, just assumed to exist\n",
        "\n",
        "\n",
        "# summary_text = \"\"\n",
        "# if os.path.exists(SUMMARY_PATH):\n",
        "#     with open(SUMMARY_PATH, \"r\", encoding=\"utf-8\") as f:\n",
        "#         summary_text = f.read()\n",
        "# else:\n",
        "#     summary_text = (\n",
        "#         \"The Cozy Oven is a small-batch, artisanal bakery that embodies slow, mindful moments.\"\n",
        "#     )\n",
        "\n",
        "# # Define where the tools will log their data\n",
        "# LEADS_LOG_PATH = \"leads_log.jsonl\"\n",
        "# FEEDBACK_LOG_PATH = \"feedback_log.jsonl\""
      ],
      "metadata": {
        "id": "P2cyYj4HR30p"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# A function used to save data into a JSON Lines file\n",
        "def _append_jsonl(path: str, record: dict) -> None:\n",
        "    os.makedirs(os.path.dirname(path) or \".\", exist_ok=True)\n",
        "    with open(path, \"a\", encoding=\"utf-8\") as f:\n",
        "        f.write(json.dumps(record, ensure_ascii=False) + \"\\n\")\n",
        "\n",
        "# Tool 1: Collecting customer info\n",
        "def record_customer_interest(email: str, name: str, message: str) -> str:\n",
        "    \"\"\"Log a potential customer lead with contact info and notes.\"\"\"\n",
        "    entry = {\n",
        "        \"timestamp\": datetime.utcnow().isoformat() + \"Z\",\n",
        "        \"name\": name,\n",
        "        \"email\": email,\n",
        "        \"message\": message,\n",
        "    }\n",
        "    _append_jsonl(LEADS_LOG_PATH, entry)\n",
        "    print(\"[LEAD RECORDED]\", entry)\n",
        "    return \"Lead recorded successfully. Thank you for your interest in The Cozy Oven!\"\n",
        "\n",
        "# Tool 2: Recording what we don't know\n",
        "def record_feedback(question: str) -> str:\n",
        "    \"\"\"Log a question or feedback when the agent cannot fully answer.\"\"\"\n",
        "    entry = {\n",
        "        \"timestamp\": datetime.utcnow().isoformat() + \"Z\",\n",
        "        \"question\": question,\n",
        "    }\n",
        "    _append_jsonl(FEEDBACK_LOG_PATH, entry)\n",
        "    print(\"[FEEDBACK RECORDED]\", entry)\n",
        "    return \"Thanks for your feedback! The Cozy Oven team will review this.\""
      ],
      "metadata": {
        "id": "39menJG8UW3n"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "System prompts"
      ],
      "metadata": {
        "id": "IANItWjaSjqA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# System prompt for the Cozy Oven agent\n",
        "system_prompt = f\"\"\"\n",
        "You are the friendly assistant for **The Cozy Oven**, a slow-life artisanal bakery.\n",
        "\n",
        "Use the business documents and your general baking knowledge to answer questions about:\n",
        "- The Cozy Oven's mission, services (Daily Lamination, Hearth Table, Bread Subscriptions), and atmosphere.\n",
        "- The team: Master Baker Ghadir and Creative Director Fatima.\n",
        "- The unique value proposition: slow, unhurried, home-away-from-home bakery experience.\n",
        "\n",
        "You have two important responsibilities:\n",
        "1. Answer questions about The Cozy Oven: menu, vibe, services, ideal customers, and how things work.\n",
        "2. Encourage and log leads:\n",
        "   - If someone sounds interested in catering, subscriptions, or planning a visit,\n",
        "     kindly invite them to share their **name**, **email**, and a short note.\n",
        "   - When they share it, call `record_customer_interest`.\n",
        "\n",
        "If you do not know the answer to a question, or if it is outside The Cozy Oven's scope,\n",
        "explain that you will pass it to the human team and call `record_feedback` with the full question.\n",
        "\n",
        "Business summary (from file):\n",
        "\n",
        "{summary_text}\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "business_tools = [\n",
        "    {\n",
        "        \"type\": \"function\",\n",
        "        \"function\": {\n",
        "            \"name\": \"record_customer_interest\",\n",
        "            \"description\": \"Record a new lead for The Cozy Oven, including contact info and what they are interested in.\",\n",
        "            \"parameters\": {\n",
        "                \"type\": \"object\",\n",
        "                \"properties\": {\n",
        "                    \"email\": {\n",
        "                        \"type\": \"string\",\n",
        "                        \"description\": \"Customer email address\"\n",
        "                    },\n",
        "                    \"name\": {\n",
        "                        \"type\": \"string\",\n",
        "                        \"description\": \"Customer full name\"\n",
        "                    },\n",
        "                    \"message\": {\n",
        "                        \"type\": \"string\",\n",
        "                        \"description\": \"Short note about what they want from The Cozy Oven\"\n",
        "                    },\n",
        "                },\n",
        "                \"required\": [\"email\", \"name\", \"message\"],\n",
        "            },\n",
        "        },\n",
        "    },\n",
        "    {\n",
        "        \"type\": \"function\",\n",
        "        \"function\": {\n",
        "            \"name\": \"record_feedback\",\n",
        "            \"description\": \"Record customer feedback or a question the assistant could not fully answer.\",\n",
        "            \"parameters\": {\n",
        "                \"type\": \"object\",\n",
        "                \"properties\": {\n",
        "                    \"question\": {\n",
        "                        \"type\": \"string\",\n",
        "                        \"description\": \"The customer's question or feedback.\"\n",
        "                    },\n",
        "                },\n",
        "                \"required\": [\"question\"],\n",
        "            },\n",
        "        },\n",
        "    },\n",
        "]\n",
        "\n",
        "# Mapping from tool name to Python function\n",
        "BUSINESS_TOOL_FUNCS = {\n",
        "    \"record_customer_interest\": record_customer_interest,\n",
        "    \"record_feedback\": record_feedback,\n",
        "}"
      ],
      "metadata": {
        "id": "3mWePwW1Srql"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Building the logic of the agent"
      ],
      "metadata": {
        "id": "ks-em45hSsdv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def run_business_agent(user_input: str, chat_history=None, max_steps: int = 5) -> str:\n",
        "    messages = [{\"role\": \"system\", \"content\": system_prompt}]\n",
        "    if chat_history:\n",
        "        for u, a in chat_history:\n",
        "            messages.append({\"role\": \"user\", \"content\": u})\n",
        "            messages.append({\"role\": \"assistant\", \"content\": a})\n",
        "    messages.append({\"role\": \"user\", \"content\": user_input})\n",
        "\n",
        "    for _ in range(max_steps):\n",
        "        response = client.chat.completions.create(\n",
        "            model=MODEL_NAME,\n",
        "            messages=messages,\n",
        "            tools=business_tools,\n",
        "            tool_choice=\"auto\",\n",
        "        )\n",
        "\n",
        "        message = response.choices[0].message\n",
        "\n",
        "        # If the AI just speaks, return the text\n",
        "        if not message.tool_calls:\n",
        "            return message.content\n",
        "\n",
        "        # If the AI requests tools, we MUST execute them and tell the AI the result\n",
        "        messages.append(message)\n",
        "        for tool_call in message.tool_calls:\n",
        "            tool_name = tool_call.function.name\n",
        "            args = json.loads(tool_call.function.arguments)\n",
        "\n",
        "            # Execute your actual python function\n",
        "            tool_func = BUSINESS_TOOL_FUNCS.get(tool_name)\n",
        "            result = tool_func(**args) if tool_func else f\"Tool {tool_name} not found.\"\n",
        "\n",
        "            # Send result back to AI\n",
        "            messages.append({\n",
        "                \"role\": \"tool\",\n",
        "                \"tool_call_id\": tool_call.id,\n",
        "                \"content\": result\n",
        "            })\n",
        "\n",
        "        # Ask the AI for a final natural response after it knows the tool worked\n",
        "        final_response = client.chat.completions.create(\n",
        "            model=MODEL_NAME,\n",
        "            messages=messages\n",
        "        )\n",
        "        return final_response.choices[0].message.content\n",
        "\n",
        "\n",
        "# def run_business_agent(user_input: str, chat_history=None, max_steps: int = 5) -> str:\n",
        "#     \"\"\"Run The Cozy Oven agent with optional chat history and tool use.\"\"\"\n",
        "#     messages = [{\"role\": \"system\", \"content\": system_prompt}]\n",
        "\n",
        "#     if chat_history:\n",
        "#         for u, a in chat_history:\n",
        "#             if u:\n",
        "#                 messages.append({\"role\": \"user\", \"content\": u})\n",
        "#             if a:\n",
        "#                 messages.append({\"role\": \"assistant\", \"content\": a})\n",
        "\n",
        "#     messages.append({\"role\": \"user\", \"content\": user_input})\n",
        "\n",
        "#     for _ in range(max_steps):\n",
        "#         response = client.chat.completions.create(\n",
        "#             model=\"gpt-4.1-mini\",\n",
        "#             messages=messages,\n",
        "#             tools=business_tools,\n",
        "#             tool_choice=\"auto\",\n",
        "#         )\n",
        "\n",
        "#         message = response.choices[0].message\n",
        "\n",
        "#         if not message.tool_calls:\n",
        "#             return message.content\n",
        "\n",
        "#         messages.append(message)\n",
        "\n",
        "#         for tool_call in message.tool_calls:\n",
        "#             tool_name = tool_call.function.name\n",
        "#             args = json.loads(tool_call.function.arguments)\n",
        "\n",
        "#             tool_func = BUSINESS_TOOL_FUNCS.get(tool_name)\n",
        "#             if tool_func is None:\n",
        "#                 tool_result = f\"Unknown tool: {tool_name}\"\n",
        "#             else:\n",
        "#                 tool_result = tool_func(**args)\n",
        "\n",
        "#             messages.append(\n",
        "#                 {\n",
        "#                     \"role\": \"tool\",\n",
        "#                     \"tool_call_id\": tool_call.id,\n",
        "#                     \"content\": tool_result,\n",
        "#                 }\n",
        "#             )\n",
        "\n",
        "\n",
        "#         followup = client.chat.completions.create(\n",
        "#             model=\"gpt-4o-mini\",\n",
        "#             messages=messages,\n",
        "#         )\n",
        "#         final_message = followup.choices[0].message\n",
        "\n",
        "#         if not final_message.tool_calls:\n",
        "#             return final_message.content\n",
        "\n",
        "#         messages.append(final_message)\n",
        "\n",
        "#     return \"I'm having trouble completing your request right now, but I've logged it for the Cozy Oven team.\""
      ],
      "metadata": {
        "id": "0EU8Vz3PSywb"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Gradio Interface"
      ],
      "metadata": {
        "id": "1bQPamRoSzcv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def gradio_business_chat(user_message, history):\n",
        "    \"\"\"Adapter between Gradio's (message, history) and our business agent.\"\"\"\n",
        "    reply = run_business_agent(user_message, chat_history=history)\n",
        "    return reply\n",
        "\n",
        "\n",
        "demo = gr.ChatInterface(\n",
        "    fn=gradio_business_chat,\n",
        "    title=\"The Cozy Oven Assistant\",\n",
        "    description=(\n",
        "        \"Chat with The Cozy Oven, a slow-life artisanal bakery. \"\n",
        "        \"Ask about our croissants, Hearth Table catering, or Flourish Locals bread subscriptions. \"\n",
        "        \"If you're interested in working with us, the assistant will politely ask for your name and email.\"\n",
        "    ),\n",
        ")\n",
        "\n",
        "# In a notebook, just call demo.launch()\n",
        "demo.launch()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 681
        },
        "id": "2hZvYCFgS8pO",
        "outputId": "d086f95e-a900-4da3-e284-bbcafad0a184"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/gradio/chat_interface.py:347: UserWarning: The 'tuples' format for chatbot messages is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style 'role' and 'content' keys.\n",
            "  self.chatbot = Chatbot(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It looks like you are running Gradio on a hosted Jupyter notebook, which requires `share=True`. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://6de92a8b7049a74043.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://6de92a8b7049a74043.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    }
  ]
}